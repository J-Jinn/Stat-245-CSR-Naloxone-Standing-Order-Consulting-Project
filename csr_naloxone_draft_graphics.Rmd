---
title: "CSR Naloxone Standing Order Project - Draft Graphics"
author: 'STAT 245, Fall 2020 (Group Members: Nana Ama Baidoo, Alex Visser, Joshua Ridder, Joseph Jinn)'
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  pdf_document:
    fig_height: 8
    fig_width: 13
  html_document:
    fig_height: 8
    fig_width: 13
classoption: landscape
---

```{r, setup, include = FALSE}
# load packages that are going to be used
require(tidyverse)
require(ggformula)
require(mosaic)
require(fastR2)
require(s245)
require(pander)
require(DHARMa)
require(glmmTMB)
require(MuMIn)
require(car)
require(dplyr) # SQL syntax ftw.
require(readr)
# require(reticulate) # Utilize Python programming language.

# Some customization.  You can alter or delete as desired (if you know what you are doing).

theme_set(theme_minimal(base_size=12))     # change theme for ggplot2/ggformula

knitr::opts_chunk$set(
  echo = TRUE,      # for homework, always show R code (this is the default)
  error = TRUE, # do not interrupt generation in case of errors,
  tidy = FALSE,     # display code as typed (rather than reformatted)
  size = "small",   # slightly smaller font for code
  message = FALSE, warning = FALSE) # don't print warnings or messages in compiled document. So you MUST check them in RStudio!
```

Note to self: Run "remotes::install_github('ProjectMOSAIC/ggformula')" to install development version of ggformula.

```{r}
# sessionInfo()
options(max.print = 6000) # Ensure we can print entire summary.
# remotes::install_github('ProjectMOSAIC/ggformula')
```

>It looks like you are off to a great start. My general recommendation is to eventually trim down some of the comments and tangents, or at least make a cleaned-up version of this file that does not document everything you tried and every thought you had in the process. It's great to have everything written down, but once you have settled on a process it is also good to have a clean file that does only that with no distractions.

___

>As for reading flat text files in R, it is easy; you can use readr::read_delim (there are other similar functions but I recommend it). The help should get you started, as it's very similar to read_csv(). The process is also documented at https://rsconnect.calvin.edu:3939/content/24/#section-other-data-file-formats (click "continue" until getting to section on "other text file formats"). I recommend avoiding python/reticulate on the RStudio server - it has issues and you're not doing anything here that is not easy to do directly in R.

[readr documentation](https://www.rdocumentation.org/packages/readr/versions/1.3.1)

[read_table documentation](https://readr.tidyverse.org/reference/read_table.html)

[read_delim documentation](https://www.rdocumentation.org/packages/readr/versions/1.3.1/topics/read_delim)

[Data Tidying Tutorial](https://rsconnect.calvin.edu:3939/content/24/#section-other-data-file-formats)

```{r}
data <- read_delim(file = "datasets//joseph_jinn_queries//deprecated//Underlying Cause of Death, 1999-2018 3.txt",
                   delim = "\t",
                   col_names = TRUE,
                   col_types = NULL,
                   na = "NA",
                   skip = 0,
                   n_max = Inf,
                   guess_max = 100,
                   progress = show_progress(),
                   comment =c("-"),
                   skip_empty_rows = TRUE
)[, -c(1)]  %>% # Ignore the "Notes" column
  filter_all(any_vars(!is.na(.)))  # Remove all rows with ALL NAs in all columns (due to "Notes" section)
```

```{r}
glimpse(data)
```

```{r}
head(data, 5)
```

```{r}
tail(data, 5)
```

Ok, the above code SHOULD work for all data query flat text files from the CDC Wonder website.

Below, re-factored into a general function for use.  Just input the filename as a string.

```{r}
parse_query <- function(file_name_as_string) {
  data <- read_delim(file = file_name_as_string,
                     delim = "\t",
                     col_names = TRUE,
                     col_types = NULL,
                     na = "NA",
                     skip = 0,
                     n_max = Inf,
                     guess_max = 100,
                     progress = show_progress(),
                     comment =c("-"),
                     skip_empty_rows = TRUE
  )[, -c(1)]  %>% # Ignore the "Notes" column
    filter_all(any_vars(!is.na(.)))  # Remove all rows with ALL NAs in all columns (due to "Notes" section)
  return(data)
}
```

Test function works as intended
```{r}
data <- parse_query("datasets//joseph_jinn_queries//deprecated//Underlying Cause of Death, 1999-2018 3.txt")
```

```{r}
glimpse(data)
```

```{r}
head(data, 5)
```

Confirmed working. =D

___

>You have the process down, and it's complicated, so great work on this. However, I think you need to work together to carefully think through what queries you need to run, how to combine them, or why not to. For example, one of the datasets in your submission doesn't include causes of death at all. So I am not sure exactly how that one would help address any of your questions about naloxone/overdoses.  

>My sense is that you have figured out how to get and read in and merge together the dataset, which really is great progress and an accomplishment. What you haven't really done yet, I don't think, is envisioned exactly how the dataset you need/want should look: what columns need to be there? And how will you build it from the pieces you have? This may be something to work through as a group, or with Laura, or I am happy to meet with you or a subset of you as well to work on it. But in my mind, figuring out how to go from a bunch of WONDER queries to one (or maybe a couple) of dataset that you can really use to address your research questions, is the key step you have to manage next.

[CDC Wonder Data Queries](https://wonder.cdc.gov/ucd-icd10.html)

[Other Data](https://www.cdc.gov/nchs/nvss/vsrr/drug-overdose-data.htm)

[Other Data](https://www.cdc.gov/drugoverdose/data/statedeaths/drug-overdose-death-2018.html)

[Basic Query Template](https://wonder.cdc.gov/controller/saved/D76/D95F252)

All settings are the same except for the GROUPBY clauses (above link to basic template used for queries)

Generate all possible combinations (corresponding to the 5 fields for Group-By in request form).
(these are essentially our variables of interest, excluding the shared variables that is common to all queries).
```{r}
level1 <- c("County", "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday",
            "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", "Single-Year Ages",
            "Five-Year Age Groups", "Ten-Year Age Groups", "2013 Urbanization")
level2 <- c("County", "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday",
            "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", "Single-Year Ages",
            "Five-Year Age Groups", "Ten-Year Age Groups", "2013 Urbanization")
level3 <- c("County", "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday",
            "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", "Single-Year Ages",
            "Five-Year Age Groups", "Ten-Year Age Groups", "2013 Urbanization")
level4 <- c("County", "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday",
            "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", "Single-Year Ages",
            "Five-Year Age Groups", "Ten-Year Age Groups", "2013 Urbanization")
level5 <- c("County", "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday",
            "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", "Single-Year Ages",
            "Five-Year Age Groups", "Ten-Year Age Groups", "2013 Urbanization")
```

We're currently interested in the above variables.

**Note: These data have already been filtered by Drug/Alcohol Induced Causes" to only include those observations before grouping by these variables.  They are also only for the state of Michigan and the years 2012-2018.  I am following the filters suggested in the project documentation provided by our project partner - CSR.  If/when we decide to explore our 3rd potential research question, then I will include All Causes of Death and filter by narcotic/non-narcotic in order to perform logistic (binary) regression modeling.**

The images below capture the current state of the basic template I am using to make the queries.  Only thing that changes is what variables I'm grouping by.

![Basic Query Template Image](images/basic_query_template.PNG)

```{r}
groupby2levels <- crossing(level1, level2)
groupby2levels <- subset(groupby2levels, level1 != level2)
groupby2levels
```

```{r}
groupby3levels <- crossing(level1, level2, level3)
groupby3levels <- subset(groupby3levels, level1 != level2 &
                           level2 != level3 &
                           level1 != level3)
groupby3levels
```

```{r}
groupby4levels <- crossing(level1, level2, level3, level4)
groupby4levels <- subset(groupby4levels, level1 != level2 &
                           level2 != level3 &
                           level3 != level4 &
                           level1 != level3 &
                           level1 != level4 &
                           level2 != level4)
groupby4levels
```

```{r}
groupby5levels <- crossing(level1, level2, level3, level4, level5)
groupby5levels <- subset(groupby5levels, level1 != level2 &
                           level2 != level3 &
                           level3 != level4 &
                           level4 != level5 &
                           level1 != level3 &
                           level1 != level4 &
                           level1 != level5 &
                           level2 != level4 &
                           level2 != level5 &
                           level3 != level5)
groupby5levels
```

Probably a more elegant and efficient way to do this, but this works.  And yea, way too many combinations of GROUPBY for queries to test.

___

#### Look at all our group-by level 1 queries:

**TODO: Need to adjust naming scheme, the datasets we're currently investigating below are ONLY for "drug" related causes of death.  I initially named it "DrugAlcoholCauses" because that's what Section 6 calls it in the selection box to specify the type of causes it should query by.**

```{r}
level1_groupby_county <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_County_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_county
```

```{r}
glimpse(level1_groupby_county)
```

```{r}
level1_groupby_gender <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_Gender_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_gender
```

```{r}
glimpse(level1_groupby_gender)
```

```{r}
level1_groupby_hispanic_origin <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_HispanicOrigin_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_hispanic_origin
```

```{r}
glimpse(level1_groupby_hispanic_origin)
```

```{r}
level1_groupby_race <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_Race_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_race
```

```{r}
glimpse(level1_groupby_race)
```

```{r}
level1_groupby_year <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_Year_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_year
```

```{r}
glimpse(level1_groupby_year)
```

```{r}
level1_groupby_month <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_Month_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_month
```

```{r}
glimpse(level1_groupby_month)
```

```{r}
level1_groupby_weekday <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_Weekday_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_weekday
```

```{r}
glimpse(level1_groupby_weekday)
```

```{r}
level1_groupby_autopsy <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_Autopsy_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_autopsy
```

```{r}
glimpse(level1_groupby_autopsy)
```

```{r}
level1_groupby_place_of_death <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_PlaceOfDeath_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_place_of_death
```

```{r}
glimpse(level1_groupby_place_of_death)
```

```{r}
level1_groupby_drug_alcohol_induced_cause <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_DrugAlcoholInducedCause_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_drug_alcohol_induced_cause
```

```{r}
glimpse(level1_groupby_drug_alcohol_induced_cause)
```


```{r}
level1_groupby_2013_urbanization <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_2013Urbanization_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_2013_urbanization
```

```{r}
glimpse(level1_groupby_2013_urbanization)
```

```{r}
level1_groupby_single_year_age <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_SingleYearAge_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_single_year_age
```

```{r}
glimpse(level1_groupby_single_year_age)
```


```{r}
level1_groupby_five_year_age_groups <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_FiveYearAgeGroups_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_five_year_age_groups
```

```{r}
glimpse(level1_groupby_five_year_age_groups)
```


```{r}
level1_groupby_ten_year_age_groups <- parse_query(
  "datasets//joseph_jinn_queries//GroupByOneLevel//CDC_GROUPBY_TenYearAgeGroups_2012_2018_Michigan_DrugAlcoholCauses.txt")
level1_groupby_ten_year_age_groups
```

```{r}
glimpse(level1_groupby_ten_year_age_groups)
```

* Common shared columns:
+ Deaths
+ Population
+ `Crude Rate`
+ `Crude Rate Lower 95% Confidence Interval`
+ `Crude Rate Upper 95% Confidence Interval`
+ `Crude Rate Standard Error`
+ `% of Total Deaths`

Unique columns are based on what we group by so I won't list them individually (refer to glimpse() above)

We should also rename columns to not have spaces and other special characters for ease with working with ggformula and other packages (so names aren't enclosed in "`").

Define function to replace "messy" column names with "clean" version.  Adjust in the future as necessary.

[R - Regular Expressions](https://rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf)

```{r}
remove_whitespace_column_names <- function(my_dataframe) {
  
  return(names(my_dataframe) %>% str_replace_all("\\s", "_") %>% 
           str_replace_all("%", "percent") %>% 
           str_replace_all("/", "_") %>% 
           str_replace_all("-", "_") %>% 
           str_replace_all("^([0-9]+)", "c\\1") %>% # Replace beginning number with dummy c - character.
           tolower)
}
```

```{r}
# colnames(level1_groupby_autopsy) <- names(level1_groupby_autopsy) %>% str_replace_all("\\s", "_") %>% 
#   str_replace_all("%", "percent") %>% str_replace_all("//", "_") %>%tolower
```


Rename columns for all datasets.

```{r}
colnames(level1_groupby_autopsy) <- remove_whitespace_column_names(level1_groupby_autopsy)
colnames(level1_groupby_county) <- remove_whitespace_column_names(level1_groupby_county)
colnames(level1_groupby_drug_alcohol_induced_cause) <- remove_whitespace_column_names(level1_groupby_drug_alcohol_induced_cause)
colnames(level1_groupby_gender) <- remove_whitespace_column_names(level1_groupby_gender)
colnames(level1_groupby_hispanic_origin) <- remove_whitespace_column_names(level1_groupby_hispanic_origin)
colnames(level1_groupby_month) <- remove_whitespace_column_names(level1_groupby_month)
colnames(level1_groupby_place_of_death) <- remove_whitespace_column_names(level1_groupby_place_of_death)
colnames(level1_groupby_race) <- remove_whitespace_column_names(level1_groupby_race)
colnames(level1_groupby_weekday) <- remove_whitespace_column_names(level1_groupby_weekday)
colnames(level1_groupby_year) <- remove_whitespace_column_names(level1_groupby_year)
colnames(level1_groupby_2013_urbanization) <- remove_whitespace_column_names(level1_groupby_2013_urbanization)
colnames(level1_groupby_single_year_age) <- remove_whitespace_column_names(level1_groupby_single_year_age)
colnames(level1_groupby_five_year_age_groups) <- remove_whitespace_column_names(level1_groupby_five_year_age_groups)
colnames(level1_groupby_ten_year_age_groups) <- remove_whitespace_column_names(level1_groupby_ten_year_age_groups)
```

Check that "%", "-", and "/" have been removed, in addition to whitespace.

```{r}
glimpse(level1_groupby_autopsy)
glimpse(level1_groupby_drug_alcohol_induced_cause)
glimpse(level1_groupby_single_year_age)
glimpse(level1_groupby_2013_urbanization)
```

___

#### Some initial draft graphics (EDA - quick and dirty):

We will use "Deaths" as our response variable when relevant as that is a column attribute across our current datasets.

```{r}
gf_point(deaths ~ autopsy, data=level1_groupby_autopsy)
```

```{r}
gf_point(as.numeric(deaths) ~ county, data=level1_groupby_county) + coord_flip()
```

```{r}
gf_point(deaths ~ drug_alcohol_induced_cause, data=level1_groupby_drug_alcohol_induced_cause) + coord_flip()
```

```{r}
gf_point(deaths ~ gender, data=level1_groupby_gender)
```

```{r}
gf_point(deaths ~ hispanic_origin, data=level1_groupby_hispanic_origin)
```

```{r}
gf_point(deaths ~ month, data=level1_groupby_month) + coord_flip()
```

```{r}
gf_point(deaths ~ place_of_death, data=level1_groupby_place_of_death) + coord_flip()
```

```{r}
gf_point(deaths ~ race, data=level1_groupby_race) + coord_flip()
```

```{r}
gf_point(deaths ~ weekday, data=level1_groupby_weekday)
```

```{r}
gf_point(deaths ~ year, data=level1_groupby_year)
```

```{r}
gf_point(deaths ~ c2013_urbanization, data=level1_groupby_2013_urbanization) + coord_flip()
```

```{r}
gf_point(as.numeric(deaths) ~ single_year_ages, data=level1_groupby_single_year_age) + coord_flip()
```
We will have to deal with the issue of "suppressed" data values.  Also, "deaths" is stored as a "chr" due to "suppressed" as a potential value.  Will need to convert to numeric type.

```{r}
gf_point(as.numeric(deaths) ~ five_year_age_groups, data=level1_groupby_five_year_age_groups) + coord_flip()
```

```{r}
gf_point(as.numeric(deaths) ~ ten_year_age_groups, data=level1_groupby_ten_year_age_groups) + coord_flip()
```

Plots aren't "pretty" but usable.

And that's it for the queries involving just one level of group-by.

___

A level 2 query that involvings grouping by two different attributes.

```{r}
level2_groupby_race_gender <- parse_query(
  "datasets//joseph_jinn_queries//GroupByTwoLevels//CDC_GROUPBY_Race_Gender_2012_2018_Michigan_DrugAlcoholCauses.txt")
level2_groupby_race_gender
```

```{r}
glimpse(level2_groupby_race_gender)
```

Fix the messy column names.

```{r}
colnames(level2_groupby_race_gender) <- remove_whitespace_column_names(level2_groupby_race_gender)
```

Confirmed fixed.

```{r}
glimpse(level2_groupby_race_gender)
```

EDA:

```{r}
gf_point(deaths ~ race | gender, data=level2_groupby_race_gender) + coord_flip()
```


[DPLYR joins](https://dplyr.tidyverse.org/reference/join.html)

[Join explanations using DPLYR](https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti)

___

Now, let's try to join the individual "Race" and "Gender" group-by tables and see what happens.

```{r}
level1_race_gender_joined <- full_join(level1_groupby_race, level1_groupby_gender)
```

```{r}
glimpse(level1_race_gender_joined)
```

```{r}
head(level1_race_gender_joined, 10)
```

```{r}
gf_point(deaths ~ race | gender, data=level1_race_gender_joined) + coord_flip()
```

Hmm, not quite what we want.  This probably won't work as we don't have access to the actual data itself.  If we did, we would probably be using the groupby() function with the dataset, which is essentially the same thing the groupby section on the CDC Wonder query request form does in order to produce the aggregate statistics.

But, if we keep grouping by more and more variables we should hopefully find interesting patterns and trends in the data...just there's a lot of possible combinations as seen above.

___

To be continued...

___

>Once you decide what variables you will be using, you will also have to deal with some formatting issues. For example, for some numeric values, the WONDER data is coded "Unreliable" when for some reason the metric can't be calculated. This means that all the numeric data in that variable gets coded as strings, and you have to force it back to numeric (which will turn the "Unreliable" entries to missing values). One way to do this is to use parse_number(Variablename).  There may be other things like this, but you first have to identify exactly which variables you'll really be using; otherwise there are just too many and you don't have time to clean them all.



___

>When I see your draft figures and/or models and can thus confirm that you've done the work described above -- choosing a set of variables to work with and making sure they are all ready to use -- I will return and update this score with no explicit revisions needed from your team.

___
___

### Section to Address Project Logistics for Friday 11/6/20

Today’s Task

Today, please spend some time with your group making a concrete plan for at least one regression model you can use to answer your research question(s). Sometimes, groups have multiple questions that can call be answered by one regression model with lots of predictors; other times, groups fit a set of several models, all with the same predictors but different repsponse variables; it all depends on your own goals (it’s not necessarily one regression model per question).

___

**Below is our list of potential research questions.  We should begin tailoring our queries to answer at minimum one question succinctly.**

* Trends in overdose deaths in Kent County compared to other counties
+ Do numbers seem to be increasing, decreasing, or staying the same after 2017?
+ Consider creating a map and tracking it over time
* Does gender, age, or race seem to have an effect on overdose rate?
+ Consider using metropolitan area as another variable.
* Compare cause of death including narcotics to non-narcotics. 
+ Has one increased as the other decreased over time?
+ Have both increased/decreased?

**I suggest we start with the first question, as it's broad and quite workable.  Also, current group suggestion is to focus on the 1st and 3rd questions.**

___

For today, identify at least one response variable you’ll need to model.

What type is the response variable? Can you use linear, count, or binary regression? (If none of these seem right - let’s talk.)

Trends in overdose deaths in Kent County compared to other counties.
>Response Variable: "deaths" (common to all queries)
Type of Response: Count data (negative binomial regression modeling or similar)

Does gender, age, or race seem to have an effect on overdose rate?
>Response Variable: "crude_rate" (by default is # of deaths per 100,000 people)
Type of Response: Continuous data (consider multiple linear regression)

Compare cause of death including narcotics to non-narcotics.
> Response variable: All Causes Of Death (subcategories: Drug Induced Causes, Alcohol Induces Causes, All other non-drug and non-alcohol causes).  
Type of Response: We could convert this into a logistic (binary) regression problem by defining success = Drug Induced Causes and failure = Alcohol Induced Causes + All other non-drug and non-alcohol causes.

___

About how many predictors can you include, given the size of the data set?

>This is going to be an issue as we are using aggregate statistics rather than actual data with individual observations.  Of course, we can group-by in ways that give us thousands of rows but whether that sort of grouping will provide useful data towards answering our research question(s) is another question entirely.

___

What predictors will you include in the model? If you have more candidates than the size of the dataset will support, you may have to prioritize.

Will you include any interactions?

**Depends on the research question(s) we choose teo pursue - TENTATIVE.**

Trends in overdose deaths in Kent County compared to other counties.
> "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday", "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", "Single-Year Ages", "Five-Year Age Groups", "Ten-Year Age Groups", and "2013 Urbanization".
We can make queries by specific county.

Does gender, age, or race seem to have an effect on overdose rate?
> "Gender", "Single-Year Ages","Five-Year Age Groups", "Ten-Year Age Groups", and "Race".
We can also consider "County, "Hispanic Origin", "Year", "Month", "Weekday", "Autopsy", "Place of Death", "Drug/Alcohol Induced Cause", , and "2013 Urbanization" if we want to look at overall effects on overdose rate.

Compare cause of death including narcotics to non-narcotics.
> "County", "Gender", "Hispanic Origin", "Race", "Year", "Month", "Weekday", "Autopsy", "Place of Death", "Single-Year Ages", "Five-Year Age Groups", "Ten-Year Age Groups", and "2013 Urbanization".

___

Focus of today - be sure to discuss carefully: should your model include any random effects? Which variable(s), specifically? If none, explain why not. If there are one or more, explain why they make sense as random effects rather than fixed effects. Finally, are they nested, or not?

```{r}
unique(level1_groupby_place_of_death$place_of_death)
```

```{r}
unique(level1_groupby_2013_urbanization$c2013_urbanization)
```

```{r}
unique(level1_groupby_hispanic_origin$hispanic_origin)
```

```{r}
unique(level1_groupby_autopsy$autopsy)
```

```{r}
unique(level1_groupby_race$race)
```

```{r}
unique(level1_groupby_drug_alcohol_induced_cause$drug_alcohol_induced_cause)
```

Again, we reiterate that while it is named "drug_alcohol_induced_cause" the cause of death is only drug-related as can be seen in the unique values above.  It's an example of terrible naming by whoever created column names for the data queries.

___

All variables currently under consideration:

"County"
"Gender"
"Hispanic Origin"
"Race"
"Year"
"Month"
"Weekday"
"Autopsy"
"Place of Death"
"Drug/Alcohol Induced Cause"
"Single-Year Ages",
"Five-Year Age Groups"
"Ten-Year Age Groups"

"2013 Urbanization" - classifies population density and other factors at the county level - pick between the 2006 or the 2013 NCHS Urban-Rural Classification Scheme for Counties. 

"deaths"
"population"

"crude_rate" - Crude Rates are expressed as the number of deaths reported each calendar year per the factor you select. The default factor is per 100,000 population, reporting the death rate per 100,000 persons. Crude Rate = Count / Population * 100,000

"percent_of_total_deaths"

___

>Trends in overdose deaths in Kent County compared to other counties.

Random Effects:

* (1 | 2013 Urbanization) - So, there could be differences in the # of deaths between urbanization classes and we would also want to generalize to the population as a whole without necessarily referencing any specific type of location class.

* (1 | County) - Similar to 2013 Urbanization above.

* (1 | 2013 Urbanization / binned Age) - The # of deaths could vary between urbanization classes and between age groups within each urbanization class.

* (1 | County / binned Age) - The # of deaths could vary between county and between age groups within each county.


Interactions:

* 2013 Urbanization and Place of Death - The type of location could determine the likely place of death as hospitals are more likely to be located in urban centers rather than rural areas, etc.

* 2013 Urbanization and Race - There could be demographic differences based on race as the socio-economic status of individuals could determine where they are more likely to live.

* 2013 Urbanization Population - The type of location probably has an effect on the population levels.  Urban areas are probably more densely populating than non-urban areas.

* Year and Population - The population of any given area definitely would change when accounting for the year.

* Place of Death and Autopsy - The place where the individual died could determine whether or not they receive an autopsy.  Then again, if there is a cause of death that probably means they did perform an autopsy already.

* Place of Death and Race - Depending on socio-economic status, some individuals might not be able to afford a hospice or nursing home.  Other similar reasoning.

* County and Place of Death - Similar to 2013 Urbanization and Place of Death.

* County and Race - Similar to 2013 Urbanization and Race.

* County and Population - Similar to 2013 Urbanization and Population.


Offsets(when applicable): 

* Not applicable.


>Does gender, age, or race seem to have an effect on overdose rate (a.k.a. "crude rate")?

Random Effects:

* Same as first research question.  Replace keyword "# of deaths" with "crude rate".


Interactions:

* None, at least when looking only at gender, race, and age.


Offsets(when applicable):

* Population - Could do an offset of deaths per unit population but this would be redundant when considering that crude rate is by default deaths per 100,000 individuals.


>Compare cause of death including narcotics to non-narcotics.

Random Effects:

* Same as first research question.  Replace keyword "# of deaths" with "cause of death".


Interactions:

* Same as first research question.  Replace keyword "# of deaths" with "cause of death".


Offsets(when applicable): 

* Not applicable.


___

Once you have settled on a plan, write it down - one easy shorthand is to write out the model formula you will use to fit the model in R.

**TODO - settle down on a concrete plan.**

#### Simple test model.

```{r}
level3_groupby_race_age_gender <- parse_query("datasets//joseph_jinn_queries//GroupByThreeLevels//CDC_GROUPBY_Age_Race_Gender_2012_2018_Michigan_DrugAlcoholCauses.txt")
```

```{r}
colnames(level3_groupby_race_age_gender) <- remove_whitespace_column_names(level3_groupby_race_age_gender)
```

```{r}
glimpse(level3_groupby_race_age_gender)
```

Notes:  Death counts are suppressed for sub-national data representing zero to nine (0-9) deaths. See Assurance of Confidentiality for more information.

Well, that suppressed data issue is a problem.

```{r}
head(level3_groupby_race_age_gender, 10)
```


```{r}
filter(level3_groupby_race_age_gender, level3_groupby_race_age_gender$single_year_ages == "20 years")
```

We have multiple observations per single age category.  2 per race for each gender for a total of 8.

NOw, to deal with those suppressed values.

```{r}
level3_groupby_race_age_gender <- level3_groupby_race_age_gender %>% 
  filter(level3_groupby_race_age_gender$deaths != "Suppressed")
```

```{r}
nrow(level3_groupby_race_age_gender)
```

Ok, we have lost quite a bit of our observations, sadly.  But, proceeding.

```{r}
gf_point(as.numeric(deaths) ~ single_year_ages | race, data=level3_groupby_race_age_gender) + coord_flip()
```

It seems we have only 2 race groups left after dropping those "Suppressed" observations.  For each age group, we still have 2 observations per race, one for "male" and the other for "female"

```{r}
gf_point(as.numeric(deaths) ~ single_year_ages | gender, data=level3_groupby_race_age_gender) + coord_flip()
```

We would expect to have 4 observations per gender per single age category, one for each of our unique races.  But alas, we have dropped a lot of the data and have only two race remaining that are accounted for.

```{r}
filter(level3_groupby_race_age_gender, level3_groupby_race_age_gender$single_year_ages == "18 years")
```

```{r}
filter(level3_groupby_race_age_gender, level3_groupby_race_age_gender$single_year_ages == "28 years")
```

```{r}
nrow(level3_groupby_race_age_gender) / 15
```

We can have up to about 13 parameters in our model by the rule of thumb.

We should probably convert our attribute/column "deaths" to a numeric type as it's currently "chr" or character type.  Also, convert other relevant attributes to factors for use in the model.

```{r}
level3_groupby_race_age_gender <- level3_groupby_race_age_gender %>% mutate(deaths_numeric = as.numeric(deaths))
level3_groupby_race_age_gender <- level3_groupby_race_age_gender %>% mutate(race_factor = as.factor(race))
level3_groupby_race_age_gender <- level3_groupby_race_age_gender %>% mutate(gender_factor = as.factor(gender))
level3_groupby_race_age_gender <- level3_groupby_race_age_gender %>% mutate(single_year_ages_factor = as.factor(single_year_ages))
```

```{r}
glimpse(level3_groupby_race_age_gender)
```

Good, we can now use a negative binomial regression model for our count data, "deaths".

```{r}
unique(level3_groupby_race_age_gender$deaths)
```

```{r}
model <- glmmTMB(deaths_numeric ~ single_year_ages_factor + race_factor + gender_factor, 
                 data = level3_groupby_race_age_gender, 
                 family = nbinom2(link = "log"))
```

FIXME: Use age groups instead to reduce parameter counts as we are over the rule of thumb maximum.  Although, we're not seeing an issues with NAs in the model summary.

```{r}
summary(model)
```

#### And some model selection...

```{r}
dredge(model)
```

```{r}
drop1(model, k = 2)
```

Based on AIC, we should keep everything as AIC values increase when removing any predictor in the model.

```{r}
drop1(model, k = log(nrow(level3_groupby_race_age_gender)))
```

Based on BIC, we should drop single_year_ages_factor as BIC values decrease when removing this predictor.

```{r}
Anova(model)
```

Based on Anova, all predictors are statistically significant.

#### And some conditions checking...

```{r}
overdisp_fun(model)
```

Over-dispersion looks good as it's below 2-3 units.

```{r}
gf_acf(~model)
```

And we have massive issues with independence of residuals in this model.


```{r}
model_sim <- simulateResiduals(model, n = 1000)
```

```{r}
gf_point(model_sim$scaledResiduals ~ fitted(model)) %>%
  gf_labs(x = "Predicted # of Deaths",
          y = 'Scaled Residuals')
```

This also isn't quite a uniform distribution in the vertical sense.

Could also check log(response variable) vs. predictors and scaled residuals vs. predictors but at this point it's clear this model fails.

But, just for kicks and giggles, here's a prediction plot based on the model above.

```{r}
t(get_fixed(model)) %>% pander()
```

Prediction plot for race_factor:
```{r}
# note: "chr" variables have unique() values, "fct" variables have level()s
model_prediction_data <- expand.grid(
  # char_variable = pull(police_stop, char_variable) %>% unique(),
  # quantitative_variable = seq(from = 0, to = 10000, by = 100),
  # categorical_variable = pull(police_stop, categorical_variable) %>% factor() %>% levels(),
  race_factor = pull(level3_groupby_race_age_gender, race_factor) %>% factor() %>% levels(),
  gender_factor = "Male",
  single_year_ages_factor = "25 years")

# compute predictions with SEs
model_predictions <- predict(model, 
                                   newdata = model_prediction_data,
                                   type = 'response', se.fit = TRUE)

glimpse(model_predictions)
```

```{r}
# add predicted values and CIs to the hypothetical dataset
model_prediction_data <- model_prediction_data %>%
  mutate(predictions = model_predictions$fit,
         CI_low = model_predictions$fit - 1.96 * model_predictions$se.fit,
         CI_hi = model_predictions$fit + 1.96 * model_predictions$se.fit)
```

```{r}
gf_point(predictions ~ race_factor, data = model_prediction_data,
         alpha = 1.0, color = "black",
         ylab="Predicted (fitted) Values",
         xlab="Race",
         title="CDC Wonder Data - Prediction Plot",
         subtitle = "",
         caption = ""
) %>%
  # gf_ribbon(CI_low + CI_hi ~ single_year_ages_factor) %>%
  gf_errorbar(CI_low + CI_hi ~ race_factor) %>%
  gf_lims(y=c(0, 200))
```

Now that I think about it, I could have just used "single_year_ages_code" instead for a quantitative predictor...

___

Might as well try it out.

```{r}
unique(level3_groupby_race_age_gender$single_year_ages_code)
```

```{r}
model2 <- glmmTMB(deaths_numeric ~ single_year_ages_code + race_factor + gender_factor, 
                 data = level3_groupby_race_age_gender, 
                 family = nbinom2(link = "log"))
```

```{r}
summary(model2)
```

#### And some model selection...

```{r}
dredge(model2)
```

```{r}
drop1(model2, k = 2)
```

Based on AIC, we should drop single_year_ages as AIC values decrease when removing this predictor.

```{r}
drop1(model2, k = log(nrow(level3_groupby_race_age_gender)))
```

Based on BIC, we should drop single_year_ages as BIC values decrease when removing this predictor.

```{r}
Anova(model2)
```

So, dropping that one predictor.

```{r}
model3 <- glmmTMB(deaths_numeric ~ race_factor + gender_factor, 
                 data = level3_groupby_race_age_gender, 
                 family = nbinom2(link = "log"))
```

```{r}
summary(model3)
```

Based on Anova, we should also drop single_year_ages as a predictor.

#### And some conditions checking...

```{r}
overdisp_fun(model3)
```

Over-dispersion looks good as it's below 2-3 units.

```{r}
gf_acf(~model3)
```

And we have massive issues with independence of residuals in this model too.


```{r}
model3_sim <- simulateResiduals(model3, n = 1000)
```

```{r}
gf_point(model3_sim$scaledResiduals ~ fitted(model3)) %>%
  gf_labs(x = "Predicted # of Deaths",
          y = 'Scaled Residuals')
```

Well, this is a uniform distribution in the vertical and the appearance makes sense as we only have categorical predictors left in our model after removing single_year_ages.

Could also check log(response variable) vs. predictors and scaled residuals vs. predictors but at this point it's clear this model fails purely from the ACF.

But, just for kicks and giggles, here's a prediction plot based on the model above.

```{r}
t(get_fixed(model3)) %>% pander()
```

Prediction plot for race_factor:
```{r}
# note: "chr" variables have unique() values, "fct" variables have level()s
model3_prediction_data <- expand.grid(
  # char_variable = pull(police_stop, char_variable) %>% unique(),
  # quantitative_variable = seq(from = 0, to = 10000, by = 100),
  # categorical_variable = pull(police_stop, categorical_variable) %>% factor() %>% levels(),
  race_factor = pull(level3_groupby_race_age_gender, race_factor) %>% factor() %>% levels(),
  gender_factor = "Male")

# compute predictions with SEs
model3_predictions <- predict(model3, 
                                   newdata = model3_prediction_data,
                                   type = 'response', se.fit = TRUE)

glimpse(model3_predictions)
```

```{r}
# add predicted values and CIs to the hypothetical dataset
model3_prediction_data <- model3_prediction_data %>%
  mutate(predictions = model3_predictions$fit,
         CI_low = model3_predictions$fit - 1.96 * model3_predictions$se.fit,
         CI_hi = model3_predictions$fit + 1.96 * model3_predictions$se.fit)
```

```{r}
gf_point(predictions ~ race_factor, data = model3_prediction_data,
         alpha = 1.0, color = "black",
         ylab="Predicted (fitted) Values",
         xlab="Race",
         title="CDC Wonder Data - Prediction Plot",
         subtitle = "",
         caption = ""
) %>%
  # gf_ribbon(CI_low + CI_hi ~ single_year_ages_factor) %>%
  gf_errorbar(CI_low + CI_hi ~ race_factor) %>%
  gf_lims(y=c(0, 200))
```

___

**The above test models gives a general sense of where we're headed.  There's still plenty of work to be done before we settle on any final model with associated graphics.**


Trends in overdose deaths in Kent County compared to other counties.

```{r}

```
___

Does gender, age, or race seem to have an effect on overdose rate?
Now, let's try to join the individual "Race" and "Gender" group-by tables and see what happens.

```{r}

```

___

Compare cause of death including narcotics to non-narcotics.
```{r}

```

___

Reporting
At the full group session at the end of today’s class, you’ll be asked to present this plan to the rest of your classmates (briefly, like 1-2 minutes).

Explain what question you are trying to answer, where your data come from, and how you designed your model. You may want to share a screen showing a glimpse() of your data, or the model formula you’re planning to use.

**Note: For this part, refer to group project proposal version 2 (csr_naloxone_group_project_proposal_v2.Rmd) and above text in this document.**

___

Spare Time?

If you have time left, here are prioritized suggestions for how to spend it:

Team coordination. Do you need to assign tasks, find times to meet, discuss progress? Do it now!

**Derp.**

Work on graphics assignment, if not already done. Do you have graphics that address all your key research questions?

**We are working on this at the moment.**

Critique work so far and make plans for improvement, including unified style/color schemes/etc.

**Data-101 course textbook "Data at Work" by Jorge Camoes is rather helpful for data visualization.  We're hypothetically meeting on Monday sometime to further flesh things out.**

Try fitting the regression model you have planned (maybe with a random effect…) and start on model assessment. You can hopefully get quick help from Prof DeRuiter if you run into any problems.

**Refer above.**

Discuss/delegate/work on revisions to project proposal or tidy dataset in response to professor’s feedback.

**We are already revising all items based on instructor feedback (I literally have the feedback in .Rmd to refer to as I work).**

___
___
___

