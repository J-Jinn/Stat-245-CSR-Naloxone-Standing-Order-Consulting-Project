---
title: "CSR Naloxone Standing Order Project - Data Cleaning, Wrangling, and Exporation (eventually)"
author: 'STAT 245, Fall 2020 (Group Members: Nana Ama Baidoo, Alex Visser, Joshua Ridder, Joseph Jinn)'
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  pdf_document:
    fig_height: 8
    fig_width: 13
  html_document:
    fig_height: 8
    fig_width: 13
classoption: landscape
---

```{r, setup, include = FALSE}
# load packages that are going to be used
require(tidyverse)
require(ggformula)
require(mosaic)
require(fastR2)
require(s245)
require(pander)
require(DHARMa)
require(glmmTMB)
require(MuMIn)
require(car)
require(dplyr) # SQL syntax ftw.
require(reticulate) # Utilize Python programming language.

# Some customization.  You can alter or delete as desired (if you know what you are doing).

theme_set(theme_minimal(base_size=12))     # change theme for ggplot2/ggformula

knitr::opts_chunk$set(
  echo = TRUE,      # for homework, always show R code (this is the default)
  error = TRUE, # do not interrupt generation in case of errors,
  tidy = FALSE,     # display code as typed (rather than reformatted)
  size = "small",   # slightly smaller font for code
  message = FALSE, warning = FALSE) # don't print warnings or messages in compiled document. So you MUST check them in RStudio!
```

Note to self: Run "remotes::install_github('ProjectMOSAIC/ggformula')" to install development version of ggformula.

```{r}
# sessionInfo()
# options(max.print = 6000) # Ensure we can print entire summary.
# remotes::install_github('ProjectMOSAIC/ggformula')
```

**Note: Could consider using Git via the integrated feature available.**

[GitHub Respository - Joseph Jinn:](https://github.com/J-Jinn/Stat-245-CSR-Naloxone-Standing-Order-Consulting-Project)

*Will not include datasets, binary, and other files in the repository, probably just the .Rmd documents*

Useful Links:

[CDC Wonder Export Help](https://wonder.cdc.gov/wonder/help/DataExport.html#Excel)
[CDC Wonder Data Queries](https://wonder.cdc.gov/ucd-icd10.html)

[Other Data](https://www.cdc.gov/nchs/nvss/vsrr/drug-overdose-data.htm)
[Other Data](https://www.cdc.gov/drugoverdose/data/statedeaths/drug-overdose-death-2018.html)

___
___

## Some Logistics for the Project:

We should probably have some kind of naming procedures for the CSV files we create from the flat text files exported from our queries from the CDC Wonder Data site.

Currently, my naming convention has become:

CDC_GROUPBY_Group1_Group2_GroupN_2012_2018_ADDITIONAL_IDENTIFIERS_HERE.csv

(i.e. CDC_GROUPBY_County_Race_2012_2018_DrugAlcoholCauses.csv)

where Group1, Group2,...,GroupN, represents the variables we are grouping by.

I'm basically specifying the structure of my query according to the different sections on the query "request form" page so that I can later identify how I created the query.  Of course, the file-name could become prohibitively long but I prefer to be able to keep track of all the different files we will accumulate rather than have generic names that don't identify at all what their contents are, which could make for analytic difficulties further on.

In addition, I am using my browser to print-to-pdf the entire "request form" tab so that I know exactly how to reproduce the query for a specific dataset file if it becomes necessary.

Currently, the naming convention for the PDF print-outs of the queries is:

Underlying Cause of Death, 1999-2018 Request Form for INSERT_NAME_OF_CSV_FILE_HERE.csv.PDF

(i.e. Underlying Cause of Death, 1999-2018 Request Form for CDC_GROUPBY_County_Race_2012_2018_DrugAlcoholCauses.csv.PDF)

So, it's basically the same static header at the beginning with the word 'for' and a copy/paste of the name of the CSV file attached with .csv and file extension .pdf.

*Eventually, we'll also probably want to break up this .Rmd into individual discrete files according to some criteria or another rather than have one super-long meta file, if we continue adding content.*

**Note: We should avoid calculating totals for columns when querying.  That is easy enough to do in R if we need column totals.  Thus, don't check the "show totals" options at the bottom of the "request form" tab.**

![CDC Wonder Data Request Form Section 7](images/CDCWonderData-RequestForm-Section7.PNG)

Other considerations:

* Set to 5 or less digits of precision in section 7 - other options.

* For "measures" in section 1, I am currently including all the "for crude rates" check-boxes, along with "age adjusted rate" and "percent of total deaths".  Could be useful...or not.

![CDC Wonder Data Request Form Section 1](images/CDCWonderData-RequestForm-Section1.PNG)

* Convert "char" types to "factor" types if it makes sense to do so (categorical variable).

* Re-level the levels in a categorical variable if a certain order makes sense (if categories are ordinal in nature).

* Re-name variables that have spaces, start with numbers, etc., as they are a pain to work with.

* Could consider using the 'reticulate' package to interface between R/Python and run code chunks in R-Studio for both languages.  Leverage the strengths of both languages.  This could be useful as I know I can write a flat text file parser in Python for our queries.**

**Note2: Current file-paths are relative and should work assuming root project directory contains this .Rmd file.  Avoid hard-coding absolute paths as that means it will only work locally on your own system.**

___
___

#### Another dataset to compare agains for our results with CDC Wonder aggregated data statistics.

```{r}
vssr <- read_csv("datasets///VSRR_Provisional_Drug_Overdose_Death_Counts.csv")
```

```{r}
glimpse(vssr)
```

Re-name columns to not have spaces and other annoyances.
```{r}
vssr <- rename(vssr, c("DataValue" = `Data Value`,
                       "PercentComplete" = `Percent Complete`,
                       "PercentPendingInvestigation" = `Percent Pending Investigation`,
                       "StateName" = `State Name`,
                       "FootnoteSymbol" = `Footnote Symbol`,
                       "PredictedValue" = `Predicted Value`
                       ))
```

```{r}
glimpse(vssr)
```

```{r}
summary(vssr)
```

```{r}
head(vssr, 5)
```

This dataset should be pretty much cleaned and ready for analysis as it was a direct download from a link provided on one of the sites listed above.  This is one of the datasets we should use to "fact check" our results using the CDC Wonder as indicated in the project documentation provided us by CSR.

```{r}
vssr_noNAs <- na.omit(vssr)
```

```{r}
nrow(vssr_noNAs)
```

There are many rows/observations with NA values in this dataset....

**TODO: Explore this dataset to better understand the variables/attributes present and how we should use it in conjunction with our primary aggregate data queries.**

[VSSR Dataset Link](https://www.cdc.gov/nchs/nvss/vsrr/drug-overdose-data.htm)

![VSSR Dataset Website - Interactive Plots](images/vssr-dataset-interactive-plots.PNG)

Might not even be necessary to mess around with that dataset and just look at the plots and other information provided about the data.


___
___

#### Test that we can import CDC Wonder query files that have been converted to CSV manually.

**TODO: Learn how to import flat text files into R, parse them into a data-frame, and export back out as a CSV.**

Note: I know enough to do this in Python, but not R yet.  Will need to look into the tutorials on the course website.

At some point, we may want to look into how to construct a function/script that knows how to automate the parsing and construction of a dataset from the flat text files that we can download from our queries on the CDC Wonder Data site.

It is kind of annoying to manually do this one at a time by hand using Microsoft Excel by importing the flat text file. Thus, recommend going this route if it doesn't prove prohibitively time-consuming.  We could also ask our project partner(s) if they already have such a script on hand as they have already been working with this data.  Albeit, they don't necessarily use R or Python so that could be a bust.


Useful Links for ETL:

[Work with Data](https://rstudio.cloud/learn/primers/2)
[Tidy Your Data](https://rstudio.cloud/learn/primers/4)
[Some Data Tidying](https://rsconnect.calvin.edu:3939/content/24/)

**TODO: Go through all these tutorials and other materials**

___


Dataset query file provided by Nana Ama Baidoo from one of her queries.

```{r}
agg1 <- read_csv("datasets//Underlying_Cause_of_Death_1999-2018.csv")
```

```{r}
glimpse(agg1)
```

```{r}
head(agg1)
```

___

Dataset query file provided by Alex Visser from one of his queries.

```{r}
agg2 <- read_csv("datasets//Underlying_Cause_of_Death_1999-2018_2.csv")
```

```{r}
glimpse(agg2)
```

```{r}
head(agg2)
```

Looks like there's no initial issues with importing the CSV files we created from flat text files from the CDC Wonder data queries.

___
___

#### Initial rough EDA to get a feel for the data.

**Note: The goal of our service-learning project is to look through as many different combinations of aggregate statistics as possible to identify relevant trends and patterns.  As such, there's no one "fixed" dataset we are working with, just experimentation with many different aggregate queries.**

```{r}
gf_point(Deaths ~ Population, data = agg1)
```

```{r}
agg1_modified <- agg1 %>% mutate(YearFactor = factor(agg1$Year), 
                                 Urbanization2013Factor = factor(agg1$`2013 Urbanization`))
```

```{r}
glimpse(agg1_modified)
```

```{r}
agg1_modified_noNAs <- drop_na(agg1_modified)
```

```{r}
gf_boxplot(Deaths ~ YearFactor, data = agg1_modified_noNAs) #+ coord_flip()
```

```{r}
gf_boxplot(Deaths ~ Urbanization2013Factor, data = agg1_modified_noNAs) + coord_flip()
```

___

```{r}
glimpse(agg2)
```

```{r}
gf_point(Deaths ~ Population, data = agg2)
```

```{r}
agg2_modified <- agg2 %>% mutate(CountyFactor = factor(agg2$County), 
                                 CauseOfDeathFactor = factor(agg2$`Cause of death`),
                                 DrugAlcoholInducedCauseFactor = factor(agg2$`Drug/Alcohol Induced Cause`))
```

```{r}
glimpse(agg2_modified)
```

```{r}
agg1_modified_noNAs <- drop_na(agg1_modified)
```

```{r}
gf_point(Deaths ~ Population | DrugAlcoholInducedCauseFactor, data = agg2_modified)
```

Below has relatively long output...

```{r}
# unique(agg2_modified$County)
```

```{r}
# unique(agg2_modified$CauseOfDeathFactor)
```

___
___

#### Some more initial rough EDA.

```{r}
agg3 <- read_csv("datasets//joseph_jinn_queries//CDC_GROUPBY_County_Gender_2012_2018_DrugAlcoholCauses.csv")
```

```{r}
glimpse(agg3)
```

```{r}
head(agg3)
```
___

```{r}
agg4 <- read_csv("datasets//joseph_jinn_queries//CDC_GROUPBY_County_Race_2012_2018_DrugAlcoholCauses.csv")
```

```{r}
glimpse(agg4)
```

```{r}
head(agg4)
```

Test merging on columns.

[DPLYR joins](https://dplyr.tidyverse.org/reference/join.html)
[Join explanations using DPLYR](https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti)

```{r}
agg_join_4_5 <- inner_join(x = agg3, y = agg4, by = "County")
```

```{r}
glimpse(agg_join_4_5)
```

```{r}
head(agg_join_4_5)
```

Well, it looks like it did indeed join on the variable I specified.  Not sure how useful it is do so in the case of these two particular datasets.  But, test successful moving on...

Need to look more into merging data together if we're asynchronously doing work and have different datasets with common columns that we could join together to have a combined dataset that contains all the different data from each individual dataset into one.  Or that's the idea...

```{r}
gf_boxplot(Deaths.x ~ Race, data = agg_join_4_5) + coord_flip()
```

```{r}
gf_boxplot(Deaths.y ~ Race, data = agg_join_4_5) + coord_flip()
```

Going to need to differentiate between Death.x and Death.y by renaming the variables.  Deaths.x is associated with the formerly separated grouped by "Gender" dataset while Death.y is associated with the formerly separated grouped by "Race" dataset.  So, in our INNER JOINED combined dataset we have for each "County", a row for each "Race" present in each "County" and each "Race" also has a row for each "Gender", if I'm interpreting correctly (getting late into the night at the moment).

I have a feeling I will enjoy data wrangling in R the more I learn and get used to it.  Might be easier than in Python using Pandas, Numpy, etc.

Hmm, could also consider using "reticulate" to run Python AND R code chunks to leverage the best of both worlds.  Would be fun to run some machine learning algorithms from Scikit-Learn.

Learned about this interface between R and Python in Data-303...

[Reticulate](https://rstudio.github.io/reticulate/)

___
___

Let's test reticulate....

**Note: Hmm, seems like R-Studio is crashing on any attempt to run Python code chunks...making Python code chunks NOT code chunks by eleminating a ` for now.**

Error Message: 

QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-jj47'
qt.qpa.screen: QXcbConnection: Could not connect to display :0
Could not connect to any X display.

``{python}
try:
print(f"hello!")
my_variable = "This is a string!"
except Exception as error:
print(error)
``

```{r}
# my_variable = "Another string."
```

``{python}
# r.my_variable
``

```{r}
# py$my_variable
```

Well, looks like using Python code chunks alongside R code chunks is a bust on Calvin's R-Studio server.  Works fine locally on my machine though.

**Note to Self: Ask Professor DeRuiter for assistance, if necessary.**

___
___

### Construct parser for CDC Wonder Data Flat Text Files...

**TODO: Finish...if possible.**

```{r}
?read.table
```


```{r}
read.table(file = "datasets//joseph_jinn_queries//Underlying Cause of Death, 1999-2018 3.txt",
           header = TRUE,
           sep = "\t"
           )
```

Hmm, need to tell R to stop reading once it hits the last observation, where the succeeding line has: "---".

This could be easier than I thought, hopefully...but going to sleep for now as it's getting late again.

___
___
___









